import gradio as gr
import asyncio
import sys
import wave
from utils_spe_rec import *
# from utils_llm import *
from utils_cam import *
from utils_robot import *
from utils_agent import *
from utils_vlm import *
from utils_vlm_move import *
from utils_tts import *
from utils_micro_bit import *
from start import command_cleaning
from pydub import AudioSegment

# # åˆå§‹åŒ–microbitä¸²å£è¿æ¥
# ser = connect_microbit()

def convert_to_wav16k1c(src_path, dst_path):
    audio = AudioSegment.from_file(src_path)
    audio = audio.set_frame_rate(16000).set_channels(1)
    audio.export(dst_path, format="wav")

def check_wav_info(audio_path):
    try:
        with wave.open(audio_path, 'rb') as wf:
            print("channels:", wf.getnchannels())
            print("framerate:", wf.getframerate())
            print("sampwidth:", wf.getsampwidth())
    except Exception as e:
        print("éŸ³é¢‘æ–‡ä»¶æ£€æŸ¥å¤±è´¥ï¼š", e)

def process_input(text, audio, image, chatbot_state):
    # åˆå§‹åŒ– history
    if chatbot_state is None:
        chatbot_state = []

    # å¤„ç†è¯­éŸ³å’Œå›¾åƒè¾“å…¥
    if audio is not None:
        tmp_path = "/tmp/converted.wav"
        convert_to_wav16k1c(audio, tmp_path)
        check_wav_info(tmp_path)
        text = recognize_speech(tmp_path)
        print("è¯­éŸ³è¯†åˆ«ç»“æœï¼š", text)
    if image is not None:
        img_desc = QwenVL_api(text, image)
        text = img_desc if not text else text + ", " + img_desc

    if not text:
        response = "è¯·æä¾›è¯­éŸ³ã€æ–‡æœ¬æˆ–å›¾ç‰‡è¾“å…¥ã€‚"
        chatbot_state.append((text, response))
        return chatbot_state, chatbot_state

    order = agent_plan(text)
    print("æ™ºèƒ½ä½“ç¼–æ’ç»“æœï¼š", order)
    order = command_cleaning(order)
    # order = order.replace("ï¼Œ", ",")  # æ›¿æ¢ä¸­æ–‡é€—å·ä¸ºè‹±æ–‡é€—å·
    # order = order.replace("ã€", ",")  # æ›¿æ¢ä¸­æ–‡é¡¿å·ä¸ºè‹±æ–‡é€—å·
    # order = order.replace("ï¼›", ";")  # æ›¿æ¢ä¸­æ–‡åˆ†å·ä¸ºè‹±æ–‡åˆ†å·
    # order = order.replace("ï¼", "!")  # æ›¿æ¢ä¸­æ–‡æ„Ÿå¹å·ä¸ºè‹±æ–‡æ„Ÿå¹å·
    # order = order.replace("ï¼Ÿ", "?")  # æ›¿æ¢ä¸­æ–‡é—®å·ä¸ºè‹±æ–‡é—®å·
    # order = order.replace("ï¼š", ":")  # æ›¿æ¢ä¸­æ–‡å†’å·ä¸ºè‹±æ–‡å†’å·
    
    try:
        agent_plan_output = eval(order)
        response = agent_plan_output['response']
        for each in agent_plan_output['function']:
            print('æ‰§è¡ŒåŠ¨ä½œ:', each)
            eval(each)
    except Exception as e:
        response = f"å‘ç”Ÿé”™è¯¯: {str(e)}"
    
    asyncio.run(text_to_speech(response))
    chatbot_state.append((text, response))  # æ›´æ–°å†å²è®°å½•
    return chatbot_state, chatbot_state

with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown(
        """
        <div align="center" style="font-size:2em; font-weight:bold; color:#4F8EF7;">
            ğŸ¤– æ™ºèƒ½æœºæ¢°è‡‚åŠ©æ‰‹
        </div>
        <div align="center" style="color:gray;">
            æ”¯æŒæ–‡æœ¬ã€è¯­éŸ³ã€å›¾ç‰‡è¾“å…¥ï¼Œä½“éªŒå¤šæ¨¡æ€AIäº¤äº’
        </div>
        """)
    with gr.Row():
        with gr.Column(scale=2):
            chatbot = gr.Chatbot(label="å¯¹è¯å†å²", height=400, show_copy_button=True)
            state = gr.State([])  # ä½¿ç”¨ State ç»„ä»¶æ¥ä¿å­˜èŠå¤©è®°å½•
            with gr.Row():
                txt = gr.Textbox(show_label=False, placeholder="è¯·è¾“å…¥æŒ‡ä»¤æˆ–é—®é¢˜", lines=2, container=True)
            submit_btn = gr.Button("ğŸš€ æäº¤", elem_id="submit-btn", scale=1)
        with gr.Column(scale=1):
            with gr.Group():
                gr.Markdown("#### è¯­éŸ³è¾“å…¥")
                audio = gr.Audio(type="filepath", label="", show_label=False)
            with gr.Group():
                gr.Markdown("#### å›¾ç‰‡è¾“å…¥")
                image = gr.Image(type="filepath", label="", show_label=False, height=180)

    submit_btn.click(
        fn=process_input,
        inputs=[txt, audio, image, state],
        outputs=[chatbot, state]  # æ›´æ–° chatbot å’Œ state
    )

demo.launch()